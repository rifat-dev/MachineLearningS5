{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHX9p5jfTySS"
      },
      "source": [
        "## Задание 5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EnHNZtbXlH0"
      },
      "source": [
        "Набор данных тут: https://github.com/sismetanin/rureviews, также есть в папке [Data](https://drive.google.com/drive/folders/1YAMe7MiTxA-RSSd8Ex2p-L0Dspe6Gs4L). Те, кто предпочитает работать с английским языком, могут использовать набор данных `sms_spam`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJox-LoonoPx"
      },
      "source": [
        "Применим полученные навыки и решим задачу анализа тональности отзывов.\n",
        "\n",
        "Нужно повторить весь пайплайн от сырых текстов до получения обученной модели.\n",
        "\n",
        "Обязательные шаги предобработки:\n",
        "1. токенизация\n",
        "2. приведение к нижнему регистру\n",
        "3. удаление стоп-слов\n",
        "4. лемматизация\n",
        "5. векторизация (с настройкой гиперпараметров)\n",
        "6. построение модели\n",
        "7. оценка качества модели\n",
        "\n",
        "Обязательно использование векторайзеров:\n",
        "1. мешок n-грамм (диапазон для n подбирайте самостоятельно, запрещено использовать только униграммы).\n",
        "2. tf-idf ((диапазон для n подбирайте самостоятельно, также нужно подбирать параметры max_df, min_df, max_features)\n",
        "3. символьные n-граммы (диапазон для n подбирайте самостоятельно)\n",
        "\n",
        "В качестве классификатора нужно использовать наивный байесовский классификатор.\n",
        "\n",
        "Для сравнения векторайзеров между собой используйте precision, recall, f1-score и accuracy. Для этого сформируйте датафрейм, в котором в строках будут разные векторайзеры, а в столбцах разные метрики качества, а в  ячейках будут значения этих метрик для соответсвующих векторайзеров."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHMiNgTYJaMC",
        "outputId": "a4a5eb61-dbc2-46c6-a110-89b83cc0d539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Data/women-clothing-accessories.csv\", sep = '\\t', usecols=[0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "iICdh7FJmShU",
        "outputId": "90fa80c1-5abc-44a2-99db-bd0e7d7b562f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9875</th>\n",
              "      <td>деньги пока не получила . шел больше месяца</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86101</th>\n",
              "      <td>Кофта подошла идеально по размеру. Описанию со...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49940</th>\n",
              "      <td>Рукава короткие, узкая в талии. Думала, матери...</td>\n",
              "      <td>neautral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50856</th>\n",
              "      <td>Слишком много push up'а</td>\n",
              "      <td>neautral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64754</th>\n",
              "      <td>Очень милый свитер. и не толстый и не тонкий, ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52296</th>\n",
              "      <td>все хорошо, но запах ! боюсь одевать</td>\n",
              "      <td>neautral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11991</th>\n",
              "      <td>продавец *удак. трек дал левый на другого чело...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55491</th>\n",
              "      <td>размер L оказался мал , еле натянула , буду на...</td>\n",
              "      <td>neautral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15153</th>\n",
              "      <td>3хл это 44 размер.мандец .на хрена такое шить?...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52115</th>\n",
              "      <td>маленький размер; не соответствует размерной с...</td>\n",
              "      <td>neautral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "9875         деньги пока не получила . шел больше месяца  negative\n",
              "86101  Кофта подошла идеально по размеру. Описанию со...  positive\n",
              "49940  Рукава короткие, узкая в талии. Думала, матери...  neautral\n",
              "50856                            Слишком много push up'а  neautral\n",
              "64754  Очень милый свитер. и не толстый и не тонкий, ...  positive\n",
              "52296               все хорошо, но запах ! боюсь одевать  neautral\n",
              "11991  продавец *удак. трек дал левый на другого чело...  negative\n",
              "55491  размер L оказался мал , еле натянула , буду на...  neautral\n",
              "15153  3хл это 44 размер.мандец .на хрена такое шить?...  negative\n",
              "52115  маленький размер; не соответствует размерной с...  neautral"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uc41mQrDoFWh",
        "outputId": "222f21d3-ee0f-4bd5-ff80-d2ee22f39971"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "neautral    21014\n",
              "negative    21007\n",
              "positive    20978\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, x_test, y_train, y_test = train_test_split(data.review, data.sentiment, train_size = 0.7)\n",
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2ZcxJAcqnzW",
        "outputId": "0fc2a735-c641-4ee7-ea30-c5e9b315df36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('нормальная', 22046),\n",
              " ('обычная', 23145),\n",
              " ('водолазка', 7247),\n",
              " ('продавец', 31866),\n",
              " ('супер', 38937),\n",
              " ('заказ', 12507),\n",
              " ('пришел', 31557),\n",
              " ('через', 43303),\n",
              " ('14', 272),\n",
              " ('дней', 10584)]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
        "vectorized_x_train = vectorizer.fit_transform(X_train)\n",
        "list(vectorizer.vocabulary_.items())[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tle6K8EvkiqN",
        "outputId": "3e9d5806-6be0-4aee-e192-3307af3a5284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    neautral       0.59      0.68      0.63      8986\n",
            "    negative       0.73      0.63      0.68      8993\n",
            "    positive       0.85      0.84      0.85      9022\n",
            "\n",
            "    accuracy                           0.72     27001\n",
            "   macro avg       0.72      0.72      0.72     27001\n",
            "weighted avg       0.72      0.72      0.72     27001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB()\n",
        "clf.fit(vectorized_x_train, y_train)\n",
        "vectorized_x_test = vectorizer.transform(x_test)\n",
        "pred = clf.predict(vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK5LrZM2lCRh"
      },
      "outputs": [],
      "source": [
        "!pip install -q pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeJemdmsmMw1"
      },
      "outputs": [],
      "source": [
        "#предобработка текста\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import string\n",
        "pymorph = MorphAnalyzer()\n",
        "# noise = stopwords.words('russian')\n",
        "# smart_vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words=noise, lowercase=True)\n",
        "# smart_vectorized_x_train = smart_vectorizer.fit_transform(X_train)\n",
        "for i in range(data.shape[0] - 1):\n",
        "  row = data.iloc[i].review\n",
        "  new_row = \"\"\n",
        "\n",
        "  for ch in string.punctuation:\n",
        "    row = row.replace(ch,\"\") # удаление этого !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "\n",
        "  tokens = word_tokenize(row)\n",
        "  for cur_token in tokens:\n",
        "    normf = pymorph.parse(cur_token)\n",
        "    new_row = new_row + normf[0].normal_form + \" \"\n",
        "  new_row = new_row[:-1]\n",
        "  data.iloc[i].review = new_row\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Z2CwJTWdnhnE",
        "outputId": "03da5e27-a059-4b24-e5b5-7a8663dce7cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9643</th>\n",
              "      <td>заказать майка 5 май сегодня 22 август заказ т...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38186</th>\n",
              "      <td>на рост 156 вес 55 маленький очень короткий</td>\n",
              "      <td>neautral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83542</th>\n",
              "      <td>маленький на 46 xl</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44518</th>\n",
              "      <td>рисунок на вещь не совпадать рукав широкий</td>\n",
              "      <td>neautral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78028</th>\n",
              "      <td>колготки отличный качество я очень понравиться...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69951</th>\n",
              "      <td>хороший джинсы такой план заказывать уже 2ой р...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78600</th>\n",
              "      <td>свитер прекрасный тёплый трек отслеживаться бы...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57036</th>\n",
              "      <td>доставка быстрый качество не устроить катышек ...</td>\n",
              "      <td>neautral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83764</th>\n",
              "      <td>платье классный прийти быстро очень понравитьс...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8726</th>\n",
              "      <td>товар так и не поступить продавец просить закр...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "9643   заказать майка 5 май сегодня 22 август заказ т...  negative\n",
              "38186        на рост 156 вес 55 маленький очень короткий  neautral\n",
              "83542                                 маленький на 46 xl  positive\n",
              "44518         рисунок на вещь не совпадать рукав широкий  neautral\n",
              "78028  колготки отличный качество я очень понравиться...  positive\n",
              "69951  хороший джинсы такой план заказывать уже 2ой р...  positive\n",
              "78600  свитер прекрасный тёплый трек отслеживаться бы...  positive\n",
              "57036  доставка быстрый качество не устроить катышек ...  neautral\n",
              "83764  платье классный прийти быстро очень понравитьс...  positive\n",
              "8726   товар так и не поступить продавец просить закр...  negative"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH0s7Z1dnrxS",
        "outputId": "42c6ae3d-6d0a-4b58-f944-c12e05c427d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(62999, 52010)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    neautral       0.59      0.64      0.61      9052\n",
            "    negative       0.71      0.63      0.67      8957\n",
            "    positive       0.81      0.83      0.82      8992\n",
            "\n",
            "    accuracy                           0.70     27001\n",
            "   macro avg       0.70      0.70      0.70     27001\n",
            "weighted avg       0.70      0.70      0.70     27001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X_train, x_test, y_train, y_test = train_test_split(data.review, data.sentiment, train_size = 0.7)\n",
        "noise = stopwords.words('russian')\n",
        "smart_vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words=noise, lowercase=True)\n",
        "smart_vectorized_x_train = smart_vectorizer.fit_transform(X_train)\n",
        "print(smart_vectorized_x_train.shape)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(smart_vectorized_x_train, y_train)\n",
        "smart_vectorized_x_test = smart_vectorizer.transform(x_test)\n",
        "pred = clf.predict(smart_vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqHTSBGXv6ku",
        "outputId": "f53bf762-921a-4595-e2b7-876c814174bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(62999, 398476)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    neautral       0.60      0.63      0.62      9052\n",
            "    negative       0.71      0.66      0.68      8957\n",
            "    positive       0.83      0.85      0.84      8992\n",
            "\n",
            "    accuracy                           0.71     27001\n",
            "   macro avg       0.71      0.71      0.71     27001\n",
            "weighted avg       0.71      0.71      0.71     27001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "smart_vectorizer_2gram = CountVectorizer(ngram_range=(1, 2), stop_words=noise, lowercase=True)\n",
        "smart_vectorized_x_train = smart_vectorizer_2gram.fit_transform(X_train)\n",
        "print(smart_vectorized_x_train.shape)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(smart_vectorized_x_train, y_train)\n",
        "smart_vectorized_x_test = smart_vectorizer_2gram.transform(x_test)\n",
        "pred = clf.predict(smart_vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFq_3pK9wf0o",
        "outputId": "02a42d8f-d5fa-4fde-8bf9-b03c38ee8604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(62999, 992025)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    neautral       0.61      0.61      0.61      9052\n",
            "    negative       0.70      0.67      0.69      8957\n",
            "    positive       0.82      0.85      0.83      8992\n",
            "\n",
            "    accuracy                           0.71     27001\n",
            "   macro avg       0.71      0.71      0.71     27001\n",
            "weighted avg       0.71      0.71      0.71     27001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "smart_vectorizer_3gram = CountVectorizer(ngram_range=(1, 3), stop_words=noise, lowercase=True)\n",
        "smart_vectorized_x_train = smart_vectorizer_3gram.fit_transform(X_train)\n",
        "print(smart_vectorized_x_train.shape)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(smart_vectorized_x_train, y_train)\n",
        "smart_vectorized_x_test = smart_vectorizer_3gram.transform(x_test)\n",
        "pred = clf.predict(smart_vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlWxW3e9Wg-m"
      },
      "source": [
        "## TF-IDF векторизация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycnF9o2Dwr3I",
        "outputId": "ca952187-5e19-410b-9ff7-d474b2f46562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    neautral       0.59      0.67      0.63      9052\n",
            "    negative       0.71      0.64      0.67      8957\n",
            "    positive       0.85      0.82      0.83      8992\n",
            "\n",
            "    accuracy                           0.71     27001\n",
            "   macro avg       0.72      0.71      0.71     27001\n",
            "weighted avg       0.72      0.71      0.71     27001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
        "tfidf_vectorized_x_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(tfidf_vectorized_x_train, y_train)\n",
        "tfidf_vectorized_x_test = tfidf_vectorizer.transform(x_test)\n",
        "pred = clf.predict(tfidf_vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egRVNfptxnWT",
        "outputId": "c514894c-101a-4f68-ecbc-1eb2a008aa44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    neautral       0.62      0.68      0.65      9052\n",
            "    negative       0.72      0.67      0.69      8957\n",
            "    positive       0.88      0.85      0.86      8992\n",
            "\n",
            "    accuracy                           0.73     27001\n",
            "   macro avg       0.74      0.73      0.73     27001\n",
            "weighted avg       0.74      0.73      0.73     27001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True)\n",
        "tfidf_vectorized_x_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(tfidf_vectorized_x_train, y_train)\n",
        "tfidf_vectorized_x_test = tfidf_vectorizer.transform(x_test)\n",
        "pred = clf.predict(tfidf_vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_IutI6_yE1w",
        "outputId": "ddee24a8-c73e-45ae-f07d-ae8d256d66b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    neautral       0.38      0.06      0.10      9052\n",
            "    negative       0.37      0.70      0.48      8957\n",
            "    positive       0.41      0.39      0.40      8992\n",
            "\n",
            "    accuracy                           0.38     27001\n",
            "   macro avg       0.39      0.38      0.33     27001\n",
            "weighted avg       0.39      0.38      0.33     27001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_df=0.9, min_df=0.3, max_features=10000)\n",
        "tfidf_vectorized_x_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(tfidf_vectorized_x_train, y_train)\n",
        "tfidf_vectorized_x_test = tfidf_vectorizer.transform(x_test)\n",
        "pred = clf.predict(tfidf_vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5o_P7PB0Kxa",
        "outputId": "b1d3d320-25e0-4c2f-d724-acb3de35c712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(62999, 27770)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    neautral       0.56      0.67      0.61      9052\n",
            "    negative       0.70      0.59      0.64      8957\n",
            "    positive       0.82      0.79      0.81      8992\n",
            "\n",
            "    accuracy                           0.68     27001\n",
            "   macro avg       0.70      0.68      0.69     27001\n",
            "weighted avg       0.70      0.68      0.69     27001\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Символьные n-граммы\n",
        "smart_vectorizer_2gram = CountVectorizer(ngram_range=(2, 3), stop_words=noise, lowercase=True, analyzer='char')\n",
        "smart_vectorized_x_train = smart_vectorizer_2gram.fit_transform(X_train)\n",
        "print(smart_vectorized_x_train.shape)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(smart_vectorized_x_train, y_train)\n",
        "smart_vectorized_x_test = smart_vectorizer_2gram.transform(x_test)\n",
        "pred = clf.predict(smart_vectorized_x_test)\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QYTwyMtWhAZ"
      },
      "source": [
        "## Задание 5.2 Регулярные выражения\n",
        "\n",
        "Регулярные выражения - способ поиска и анализа строк. Например, можно понять, какие даты в наборе строк представлены в формате DD/MM/YYYY, а какие - в других форматах.\n",
        "\n",
        "Или бывает, например, что перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
        "\n",
        "Навык полезный, давайте в нём тоже потренируемся.\n",
        "\n",
        "Для работы с регулярными выражениями есть библиотека **re**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaUW5S4gWhAb"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6aYh7Osl8xr"
      },
      "source": [
        "В регулярных выражениях, кроме привычных символов-букв, есть специальные символы:\n",
        "* **?а** - ноль или один символ **а**\n",
        "* **+а** - один или более символов **а**\n",
        "* **\\*а** - ноль или более символов **а** (не путать с +)\n",
        "* **.** - любое количество любого символа\n",
        "\n",
        "Пример:\n",
        "Выражению \\*a?b. соответствуют последовательности a, ab, abc, aa, aac НО НЕ abb!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7zOFFA3l_KQ"
      },
      "source": [
        "Рассмотрим подробно несколько наиболее полезных функций:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbJrUpARWhAd"
      },
      "source": [
        "### findall\n",
        "возвращает список всех найденных непересекающихся совпадений.\n",
        "\n",
        "Регулярное выражение **ab+c.**:\n",
        "* **a** - просто символ **a**\n",
        "* **b+** - один или более символов **b**\n",
        "* **c** - просто символ **c**\n",
        "* **.** - любой символ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2athHzKuWhAd",
        "outputId": "5810876e-98a1-48b4-80ef-15b80c7d0e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abcd', 'abca']\n"
          ]
        }
      ],
      "source": [
        "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc')\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9FpIw5RWhAf"
      },
      "source": [
        "Вопрос на внимательность: почему нет abcx?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5ttzoxEWhAg"
      },
      "source": [
        "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZR2AEq3WhAg",
        "outputId": "485760cb-168a-4e08-df93-44b5c1416fb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['wo', 'on', 'Ti', 'Tu', 'th', 'Oc', 'wi', 'so', 've', 'de', 'bl', 'op', 'pl', 'ag', 'Pe', 'Sv', 'an', 'An', 'Ta']\n"
          ]
        }
      ],
      "source": [
        "text = \"I won one Titled Tuesday this Oct with some very decent black opening play against Peter Svidler and Andrew Tang.\"\n",
        "print(re.findall(r'\\b[A-Za-z]\\S', text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI18l-l9WhAk"
      },
      "source": [
        "### split\n",
        "разделяет строку по заданному шаблону\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVKdRoc1WhAl",
        "outputId": "ba28f6e6-d448-4769-e6de-a2ccdaa8c6c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['itsy', ' bitsy', ' teenie', ' weenie']\n"
          ]
        }
      ],
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie')\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10u5efuSWhAm"
      },
      "source": [
        "можно указать максимальное количество разбиений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U9EQZMwWhAn",
        "outputId": "c2c52c46-8b37-4931-d1f1-ca469d69c419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['itsy', ' bitsy, teenie, weenie']\n"
          ]
        }
      ],
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit=1)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EMcMyflWhAp"
      },
      "source": [
        "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVgPSjEOWhAp",
        "outputId": "15d3ac7e-f6c8-4664-9cc4-553a68c6c768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I won one Titled Tuesday this Oct with some very decent black opening play against Peter Svidler and Andrew Tang', ' Both were critical games for winning this Titled Tuesday', \"  Here's some “blitz” commentary for these 3|1 games.\"]\n"
          ]
        }
      ],
      "source": [
        "text = \"I won one Titled Tuesday this Oct with some very decent black opening play against Peter Svidler and Andrew Tang. Both were critical games for winning this Titled Tuesday.  Here's some “blitz” commentary for these 3|1 games.\"\n",
        "list = re.split('\\.', text, maxsplit=2)\n",
        "print(list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wrEGqBSWhAr"
      },
      "source": [
        "### sub\n",
        "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
        "\n",
        "параметры: (pattern, repl, string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az3KxKWwWhAr",
        "outputId": "a21e797c-fc1b-4448-a918-c979a644c17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bbcbbc\n"
          ]
        }
      ],
      "source": [
        "result = re.sub('a', 'b', 'abcabc')\n",
        "print (result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD0n7_HPWhAt"
      },
      "source": [
        "**Задание**: напишите регулярное выражение, которое позволит заменить все цифры в строке на \"DIG\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Sdu7xlWhAu",
        "outputId": "909581a1-7411-4e88-9de1-f9adb8fbf78c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DIGITAL November\n"
          ]
        }
      ],
      "source": [
        "text = \"2ITAL November\"\n",
        "print(re.sub('\\d', 'DIG', text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8__oi1PWhAv"
      },
      "source": [
        "**Задание**: напишите  регулярное выражение, которое позволит убрать url из строки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwNS9zt4WhAv",
        "outputId": "bed28ed1-f2ec-4d26-cadf-11a78d1bdfd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021ITAL November  December\n"
          ]
        }
      ],
      "source": [
        "text = \"2021ITAL November https://vk.com/al_feed.php December\"\n",
        "print(re.sub(r'https://[^\\s]+', '', text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gStgBJy2WhAx"
      },
      "source": [
        "### compile\n",
        "компилирует регулярное выражение в отдельный объект"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JstTupisWhAy",
        "outputId": "51982730-7216-4717-e9ff-c02bdd648858"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Пример: построение списка всех слов строки:\n",
        "prog = re.compile('[А-Яа-яё\\-]+')\n",
        "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEXc3G0WhA2"
      },
      "source": [
        "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFvnIWbUWhA2",
        "outputId": "3f8e63df-78d6-47bc-e901-3a3b301fe7d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Слова', 'больше', 'больше', 'слов', 'Что-то']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prog = re.compile(r'[А-Яа-яё\\-]{4,}')\n",
        "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQDNZ3HQWhA3"
      },
      "source": [
        "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
        "\n",
        "```\n",
        "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cer2TZP57S5g",
        "outputId": "eda8c990-261f-40cb-cae0-8fe9cd6c6433"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['@test.in', '@analyticsvidhya.com', '@rest.biz']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "prog = re.compile(r'@[a-zA-Z]+\\.[a-zA-Z]{2,5}\\b')\n",
        "prog.findall(\"abc.test@gmail.comkdjfhvdfiv, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMyTAXK1E60x",
        "outputId": "6338c169-a07d-491d-b48d-29e6935d17f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1966\n"
          ]
        }
      ],
      "source": [
        "print(re.sub(r'\\b\\d{1,2} [A-Z][a-z]{1,} ', '', '1 April 1966'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Zpq4QOU5Wg-H",
        "i_7DyyXRWg-K",
        "_JewKs4XU-so",
        "5yiLk1P_xYQ2",
        "VlWxW3e9Wg-m",
        "D39SSh0zWg-r",
        "rhVrgkSaWg_K",
        "XsRf9T_SWg_U",
        "ylKZG2MwWg_f",
        "9hedBdcYWhAH",
        "JrqW55jgWhAR",
        "5QYTwyMtWhAZ",
        "DbJrUpARWhAd",
        "MI18l-l9WhAk",
        "1wrEGqBSWhAr",
        "gStgBJy2WhAx"
      ],
      "name": "Копия блокнота \"lab5.ipynb\"",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
